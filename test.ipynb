{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "USE_CUDA = torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vocab(src):\n",
    "    word2idx = {}\n",
    "    idx2word = {}\n",
    "    for i,w in enumerate(open(src).read().splitlines()):\n",
    "        if w not in word2idx:\n",
    "            word2idx[w] = i\n",
    "            idx2word[i] = w\n",
    "    return word2idx, idx2word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab_src = \"./Data/vocab.en.txt\"\n",
    "vi_vocab_src = \"./Data/vocab.vi.txt\"\n",
    "train_en_src = \"./Data/train.en.txt\"\n",
    "train_vi_src = \"./Data/train.vi.txt\"\n",
    "valid_en_src = \"./Data/valid.en.txt\"\n",
    "valid_vi_src = \"./Data/valid.vi.txt\"\n",
    "test_en_src = \"./Data/test10.en.txt\"\n",
    "test_vi_src = \"./Data/test10.vi.txt\"\n",
    "\n",
    "source_vocab, idx2source = read_vocab(en_vocab_src)\n",
    "target_vocab, idx2target = read_vocab(vi_vocab_src)\n",
    " \n",
    "MAX_LEN = 100 # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb\n",
    "# s_data = open(valid_en_src, \"rb\")\n",
    "# for l in s_data:\n",
    "#     print(l.split())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator(s_src, t_src, s_vocab, t_vocab, max_sent_len=MAX_LEN, batch_size=1, num_sample=0):\n",
    "    s_data = open(s_src, \"r\").readlines()\n",
    "    t_data = open(t_src, \"r\").readlines()\n",
    "    if num_sample:\n",
    "        idx = random.sample(range(len(s_data)), num_sample)\n",
    "        s_data = np.array(s_data)[idx]\n",
    "        t_data = np.array(t_data)[idx]\n",
    "    f = lambda x: Variable(torch.LongTensor(x).view(1,-1))\n",
    "    out_source, out_target, len_source, len_target = [], [], [], []\n",
    "    batch_idx = 0\n",
    "    for i, (s_line, t_line) in enumerate(zip(s_data, t_data)):\n",
    "        if i - batch_idx >= batch_size:\n",
    "            yield out_source, out_target, len_source, len_target\n",
    "            out_source, out_target, len_source, len_target = [], [], [], []\n",
    "            batch_idx = i\n",
    "        a_source = [ s_vocab[w] if w in s_vocab else s_vocab[\"<unk>\"] \n",
    "                      for w in s_line.replace(\"\\n\", \"\").split(\" \")][:max_sent_len] ## could do reverse the input\n",
    "        a_target = [ t_vocab[w] if w in t_vocab else t_vocab[\"<unk>\"] \n",
    "                      for w in t_line.replace(\"/n\", \"</s>\").split()]\n",
    "        a_target.insert(0,t_vocab[\"<s>\"])\n",
    "        var_source = f(a_source).cuda() if USE_CUDA else f(a_source)\n",
    "        var_target = f(a_target).cuda() if USE_CUDA else f(a_target)\n",
    "        out_source.append(var_source)\n",
    "        out_target.append(var_target)\n",
    "        if (i+1)%batch_size == 0:\n",
    "            yield (out_source), (out_target), len_source, len_target\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data = data_iterator(train_en_src, train_vi_src,source_vocab, target_vocab)\n",
    "# for d, s,_,_ in data:\n",
    "#     print(\"source len:\", len(d))\n",
    "#     print(\"target len:\", len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bidirectional=False):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bi = bidirectional\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers = num_layers, bidirectional = self.bi)\n",
    "\n",
    "    def forward(self, word_inputs, hidden=None):\n",
    "        word_inputs = word_inputs.cuda() if USE_CUDA else word_inputs\n",
    "        seq_len = len(word_inputs)\n",
    "        embedded = self.embedding(word_inputs).view(seq_len, 1, -1)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        direction = 2 if self.bi else 1\n",
    "        result = Variable(torch.zeros(self.num_layers*direction, 1, self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.atten = nn.Linear(2*hidden_size, hidden_size)\n",
    "        self.w = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "    \n",
    "    def forward(self, encoder_outputs, hidden):\n",
    "        encoder_outputs = encoder_outputs.cuda() if USE_CUDA else \\\n",
    "            encoder_outputs\n",
    "        source_len = len(encoder_outputs)\n",
    "        atten_all = Variable(torch.zeros(source_len))\n",
    "        if USE_CUDA:\n",
    "            atten_all = atten_all.cuda()\n",
    "\n",
    "        for i in range(source_len):\n",
    "            atten_all[i] = self.score(hidden.unsqueeze(0), encoder_outputs[i])\n",
    "        return self.softmax(atten_all).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    def score(self, hidden, encoder_outputs):\n",
    "        res = self.atten(torch.cat((hidden.view(1,-1), encoder_outputs), 1)) ## linear\n",
    "        res = self.w.dot(res)\n",
    "        return res\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size*2, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "        self.atten = Attention(hidden_size)\n",
    "\n",
    "    def forward(self, input, last_context, last_hidden, encoder_outputs):\n",
    "        input = input.cuda() if USE_CUDA else input\n",
    "        embedded = self.embedding(input).view(1,1,-1)\n",
    "       \n",
    "        rnn_input = torch.cat((embedded, last_context.unsqueeze(0)), 2)  # combine embedding and last context\n",
    "        rnn_output, hidden = self.gru(rnn_input, last_hidden)\n",
    "        weights = self.atten(encoder_outputs, hidden) # get weights\n",
    "        context = weights.bmm(encoder_outputs.transpose(0, 1)) \n",
    "        \n",
    "        rnn_output = rnn_output.squeeze(0) # 1 x B x N -> B x N\n",
    "        context = context.squeeze(1)       # B x 1 x N -> B x N\n",
    "        \n",
    "        output = self.softmax(self.out(torch.cat((rnn_output, context), 1)))\n",
    "        return output, context, hidden, weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(self.num_layers, 1, self.hidden_size))\n",
    "        if USE_CUDA:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(encoder, decoder, criterion, encoder_opt, decoder_opt, atten_opt, debug=True):\n",
    "    total_len = 0\n",
    "    total_loss = 0\n",
    "    data = None\n",
    "    if debug:\n",
    "        data = data_iterator(valid_en_src, valid_vi_src,source_vocab, target_vocab)\n",
    "    else:\n",
    "        data =  data_iterator(train_en_src, train_vi_src,source_vocab, target_vocab)\n",
    "\n",
    "    for source, target, _, _ in data:\n",
    "        for s, t in zip(source, target):\n",
    "            s = s.view(-1)\n",
    "            t = t.view(-1)\n",
    "            target_len = t.size()[0]\n",
    "            \n",
    "            encoder_hidden = encoder.initHidden()\n",
    "            encoder_opt.zero_grad()\n",
    "            decoder_opt.zero_grad()\n",
    "        \n",
    "            encoder_outputs = Variable(torch.zeros(MAX_LEN, encoder.hidden_size))\n",
    "            encoder_outputs = encoder_outputs.cuda() if USE_CUDA else encoder_outputs\n",
    "            encoder_output = None\n",
    "            \n",
    "            loss = 0\n",
    "            criterion = nn.NLLLoss()\n",
    "            encoder_outputs, encoder_hidden = encoder(s, encoder_hidden)\n",
    "            decoder_hidden = encoder_hidden\n",
    "            decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "            decoder_context = decoder_context.cuda() if USE_CUDA else decoder_context\n",
    "            \n",
    "            for de_i in range(target_len):\n",
    "                decoder_output, context, hidden, weights = decoder(t[de_i], decoder_context, decoder_hidden, encoder_outputs)\n",
    "#                 print(decoder_output.size())\n",
    "#                 print(t[de_i].size())\n",
    "                loss += criterion(decoder_output, t[de_i]) # need 2D of output\n",
    "                decoder_context = context\n",
    "                decoder_hidden = hidden\n",
    "        \n",
    "            loss.backward() \n",
    "            # Prevent gradient explosion if happens\n",
    "            torch.nn.utils.clip_grad_norm(decoder.parameters(), 0.25)\n",
    "            torch.nn.utils.clip_grad_norm(encoder.parameters(), 0.25)\n",
    "            torch.nn.utils.clip_grad_norm(decoder.atten.parameters(), 0.25)\n",
    "            \n",
    "            encoder_opt.step()\n",
    "            decoder_opt.step()\n",
    "            atten_opt.step()\n",
    "            \n",
    "            total_len += target_len\n",
    "            total_loss += loss.data[0]\n",
    "    if total_len == 0:\n",
    "        return 0\n",
    "    return total_loss/total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, en_sentence, vi_sentence):\n",
    "    # Run through encoder\n",
    "    encoder_hidden = encoder.initHidden()    \n",
    "    encoder_outputs, encoder_hidden = encoder(en_sentence.view(-1), encoder_hidden)\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = vi_sentence.view(-1)\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "    decoder_input = decoder_input.cuda() if USE_CUDA else decoder_input\n",
    "    decoder_context = decoder_context.cuda() if USE_CUDA else decoder_context\n",
    "\n",
    "    decoder_hidden = encoder_hidden.clone().view(1,1,-1)\n",
    "    decoded_words = []\n",
    "    criterion = nn.NLLLoss()\n",
    "    loss  = 0\n",
    "    # Run through decoder\n",
    "    for di in range(decoder_input.size()[0]):\n",
    "        decoder_output, decoder_context, decoder_hidden, weights = decoder(decoder_input[di], decoder_context, decoder_hidden, encoder_outputs)\n",
    "        loss +=criterion(decoder_output.view(1,-1), decoder_input[di].view(-1)).data[0]\n",
    "        \n",
    "#         # Choose top word from output\n",
    "#         topv, topi = decoder_output.data.topk(1)\n",
    "#         ni = topi[0][0]\n",
    "#         ni = Variable(torch.LongTensor([ni]))\n",
    "#         vi_sentence = vi_sentence.squeeze(0)\n",
    "#         print(vi_sentence.size())\n",
    "#         print(ni.size())\n",
    "#         loss += criterion(decoder_output.view(1,-1), vi_sentence[di].view(-1))\n",
    "#         if ni == target_vocab['</s>']:\n",
    "#             break\n",
    "#         else:\n",
    "#             decoded_words.append(idx2target[ni])  \n",
    "#         # Choose next input word\n",
    "#         decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "#         decoder_input = decoder_input.cuda()  if USE_CUDA else decoder_input\n",
    "        \n",
    "    return decoded_words, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, n_epoches=200, learning_rate=0.01,):\n",
    "    encoder_opt = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_opt = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    atten_opt = optim.SGD(decoder.atten.parameters(), lr=learning_rate)\n",
    "       \n",
    "    criterion = nn.NLLLoss()\n",
    "    total_loss = 0\n",
    "    print_loss = 0\n",
    "    loss = 0\n",
    "    print_every_ep = 1\n",
    "    for ep in range(1, n_epoches+1):\n",
    "        loss = train_one(encoder, decoder, criterion, encoder_opt, decoder_opt, atten_opt)\n",
    "        total_loss += loss\n",
    "        print_loss += loss\n",
    "        \n",
    "        if ep % print_every_ep == 0:\n",
    "            loss_avg = print_loss/print_every_ep\n",
    "            print_loss = 0\n",
    "#             print(\"epoch:{}, train_loss:{}\".format(ep, loss_avg))\n",
    "            data = data_iterator(train_en_src, train_vi_src,source_vocab, target_vocab)\n",
    "            total_test_loss = 0\n",
    "            num_test = 0\n",
    "            for test_en_batch, test_vi_batch, _, _ in data:\n",
    "                for test_en, test_vi in zip(test_en_batch, test_vi_batch):\n",
    "                    test_en = test_en.view(1,1,-1)\n",
    "                    test_vi = test_vi.view(1,1,-1)\n",
    "                    _, test_loss = evaluate(encoder, decoder, test_en, test_vi)\n",
    "                    total_test_loss += test_loss\n",
    "                    num_test += 1\n",
    "            test_loss = total_test_loss/num_test\n",
    "            print(\"epoch:{}, train_loss:{}, test_loss:{}\".format(ep, round(loss_avg,3), round(test_loss,3)))\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, train_loss:8.93, test_loss:358.328\n",
      "epoch:2, train_loss:8.913, test_loss:364.43\n",
      "epoch:3, train_loss:8.896, test_loss:774.058\n",
      "epoch:4, train_loss:8.88, test_loss:341.658\n",
      "epoch:5, train_loss:8.863, test_loss:409.665\n",
      "epoch:6, train_loss:8.846, test_loss:445.49\n",
      "epoch:7, train_loss:8.829, test_loss:169.667\n",
      "epoch:8, train_loss:8.814, test_loss:527.144\n",
      "epoch:9, train_loss:8.797, test_loss:279.404\n",
      "epoch:10, train_loss:8.78, test_loss:274.68\n",
      "epoch:11, train_loss:8.763, test_loss:452.04\n",
      "epoch:12, train_loss:8.746, test_loss:331.889\n",
      "epoch:13, train_loss:8.729, test_loss:287.017\n",
      "epoch:14, train_loss:8.712, test_loss:264.914\n",
      "epoch:15, train_loss:8.695, test_loss:623.572\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9bb9687bc695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# encoder = EncoderRNN(1000, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# decoder = DecoderRNN(hidden_size,1000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-acdbb854bf5a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, n_epoches, learning_rate)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint_every_ep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoches\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matten_opt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-6ffd6a0a947f>\u001b[0m in \u001b[0;36mtrain_one\u001b[0;34m(encoder, decoder, criterion, encoder_opt, decoder_opt, atten_opt, debug)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;31m# Prevent gradient explosion if happens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "### Training\n",
    "\n",
    "hidden_size = 256\n",
    "encoder = EncoderRNN(len(source_vocab), hidden_size)\n",
    "encoder = encoder.cuda() if USE_CUDA else encoder\n",
    "decoder = DecoderRNN(hidden_size, len(target_vocab))\n",
    "decoder = decoder.cuda() if USE_CUDA else decoder\n",
    "# encoder = EncoderRNN(1000, hidden_size)\n",
    "# decoder = DecoderRNN(hidden_size,1000)\n",
    "train(encoder, decoder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
